#!/usr/bin/env python3
"""
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: å¾“æ¥å‡¦ç†ï¼ˆè©±è€…æƒ…å ±ãªã—ï¼‰

_structured.json ã‹ã‚‰ç›´æ¥è¦ç´„ãƒ»ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒç”¨
"""

import json
import sys
import os
import time
from pathlib import Path
import google.generativeai as genai
from datetime import datetime
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# Gemini APIè¨­å®š
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY environment variable not set")

genai.configure(api_key=GEMINI_API_KEY)

# ç„¡æ–™ãƒ—ãƒ©ãƒ³ã§ä½¿ç”¨å¯èƒ½ãªé«˜é€Ÿãƒ¢ãƒ‡ãƒ«
MODEL_NAME = 'gemini-2.0-flash-exp'

def summarize_segments_baseline(segments, window_size=10):
    """
    ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¦ç´„ï¼ˆè©±è€…æƒ…å ±ãªã—ã€åŸºæœ¬çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ï¼‰
    """
    model = genai.GenerativeModel(MODEL_NAME)
    summarized = []

    for i in range(0, len(segments), window_size):
        window = segments[i:i+window_size]

        # è©±è€…æƒ…å ±ã‚’å«ã‚ãªã„ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆ
        conversation = "\n".join([seg['text'] for seg in window])

        # åŸºæœ¬çš„ãªè¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰
        prompt = f"""ä»¥ä¸‹ã®ä¼šè©±ã‚’ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ä¼šè©±:
{conversation}

è¦ç´„:"""

        response = model.generate_content(
            prompt,
            generation_config={'temperature': 0.3}
        )

        summary_text = response.text.strip()

        summary_segment = {
            'id': i // window_size + 1,
            'original_segment_ids': [seg['id'] for seg in window],
            'text': summary_text,
            'timestamp': window[0]['timestamp'],
            'original_segments_count': len(window)
        }

        summarized.append(summary_segment)

        print(f"   Summarized segments {window[0]['id']}-{window[-1]['id']} ({len(window)} segments)")

        # Rate limitå¯¾ç­–: 6ç§’å¾…æ©Ÿï¼ˆ10 req/minï¼‰
        time.sleep(6)

    return summarized

def extract_topics_baseline(full_text):
    """
    å…¨æ–‡ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆåŸºæœ¬çš„ãªæŠ½å‡ºã®ã¿ï¼‰
    """
    model = genai.GenerativeModel(MODEL_NAME)

    prompt = f"""ä»¥ä¸‹ã®ä¼šè©±ã‹ã‚‰ã€ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ä¼šè©±:
{full_text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
  "topics": ["ãƒˆãƒ”ãƒƒã‚¯1", "ãƒˆãƒ”ãƒƒã‚¯2", ...]
}}"""

    response = model.generate_content(
        prompt,
        generation_config={
            'temperature': 0.1,
            'response_mime_type': 'application/json'
        }
    )

    return json.loads(response.text)

def generate_filename_baseline(original_filename, topics):
    """
    åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆæ—¥ä»˜ + ãƒˆãƒ”ãƒƒã‚¯ï¼‰
    """
    model = genai.GenerativeModel(MODEL_NAME)

    prompt = f"""ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰ã€é©åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«å: {original_filename}
ãƒˆãƒ”ãƒƒã‚¯: {', '.join(topics[:3])}

ãƒ•ã‚¡ã‚¤ãƒ«åã¯ä»¥ä¸‹ã®å½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„:
MM-DD ãƒˆãƒ”ãƒƒã‚¯1ã¨ãƒˆãƒ”ãƒƒã‚¯2

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
  "filename": "ç”Ÿæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å"
}}"""

    response = model.generate_content(
        prompt,
        generation_config={
            'temperature': 0.3,
            'response_mime_type': 'application/json'
        }
    )

    result = json.loads(response.text)
    return result['filename']

def baseline_pipeline(input_file):
    """
    ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
    """
    start_time = time.time()

    print("="*80)
    print("ğŸ”µ Baseline Pipeline (No Speaker Info, Basic Prompts)")
    print("="*80)

    print(f"\nğŸ“‚ Loading: {input_file}")

    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    segments = data['segments']
    file_name = data['metadata']['file']['file_name']

    # Step 1: è¦ç´„ç”Ÿæˆ
    print(f"\nğŸ” Summarizing {len(segments)} segments (baseline method)...")
    summarized_segments = summarize_segments_baseline(segments, window_size=10)
    print(f"âœ… Created {len(summarized_segments)} summary segments")

    # Step 2: ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º
    print(f"\nğŸ” Extracting topics (baseline method)...")
    full_text = "\n".join([seg['text'] for seg in segments])
    topics_result = extract_topics_baseline(full_text)
    topics = topics_result.get('topics', [])
    print(f"âœ… Extracted {len(topics)} topics")

    # Step 3: ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
    print(f"\nğŸ” Generating filename (baseline method)...")
    generated_filename = generate_filename_baseline(file_name, topics)
    print(f"âœ… Generated filename: {generated_filename}")

    # å®Ÿè¡Œæ™‚é–“è¨ˆç®—
    execution_time = time.time() - start_time

    # çµæœã‚’ã¾ã¨ã‚ã‚‹
    result = {
        'metadata': {
            'input_file': input_file,
            'original_filename': file_name,
            'processed_at': datetime.now().isoformat(),
            'method': 'baseline',
            'model': MODEL_NAME,
            'execution_time_seconds': execution_time
        },
        'segments': segments,  # å…ƒã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä¿æŒ
        'summarized_segments': summarized_segments,
        'topics': topics,
        'generated_filename': generated_filename,
        'statistics': {
            'segment_count': len(segments),
            'summary_count': len(summarized_segments),
            'topic_count': len(topics),
            'filename_length': len(generated_filename),
            'total_chars': sum(len(seg['text']) for seg in segments),
            'summary_chars': sum(len(seg['text']) for seg in summarized_segments)
        }
    }

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    output_file = input_file.replace('_structured.json', '_baseline_result.json')

    print(f"\nğŸ’¾ Saving to: {output_file}")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… Baseline Pipeline Complete!")
    print(f"   Execution time: {execution_time:.1f} seconds")

    return output_file

def main():
    if len(sys.argv) < 2:
        print("Usage: python baseline_pipeline.py <structured.json>")
        sys.exit(1)

    input_file = sys.argv[1]

    if not os.path.exists(input_file):
        print(f"Error: File not found: {input_file}")
        sys.exit(1)

    baseline_pipeline(input_file)

if __name__ == '__main__':
    main()
