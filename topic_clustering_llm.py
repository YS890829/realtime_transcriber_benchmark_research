#!/usr/bin/env python3
"""
Phase 6-3 Stage 4-1: LLMãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
Gemini 2.0 Flash ã‚’ä½¿ç”¨ã—ã¦ã€ãƒˆãƒ”ãƒƒã‚¯ã‚’æ„å‘³çš„ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

æ©Ÿèƒ½:
- Gemini APIã§23å€‹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æ
- æ–‡è„ˆç†è§£ã«ã‚ˆã‚‹é«˜ç²¾åº¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
- ã‚«ãƒ†ã‚´ãƒªåã®è‡ªå‹•ç”Ÿæˆ
- ç†ç”±ä»˜ãã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
"""

import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any
from collections import defaultdict
from dotenv import load_dotenv
import google.generativeai as genai

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Gemini APIã‚­ãƒ¼é¸æŠï¼ˆFREE/PAID tierï¼‰
use_paid_tier = os.getenv("USE_PAID_TIER", "").lower() == "true"
api_key = os.getenv("GEMINI_API_KEY_PAID") if use_paid_tier else os.getenv("GEMINI_API_KEY")

if not api_key:
    print("âŒ Error: GEMINI_API_KEY not found in environment variables")
    sys.exit(1)

genai.configure(api_key=api_key)
print(f"âœ… Using Gemini API: {'PAID' if use_paid_tier else 'FREE'} tier")


class LLMTopicClusterer:
    """LLMãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.model = genai.GenerativeModel("gemini-2.0-flash-exp")

        print("âœ… LLM Topic Clusterer initialized")
        print("   Model: gemini-2.0-flash-exp")

    def load_topics_from_json(self, json_paths: List[str]) -> List[Dict[str, Any]]:
        """
        è¤‡æ•°ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿

        Args:
            json_paths: JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ

        Returns:
            ãƒˆãƒ”ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆï¼ˆé‡è¤‡ãªã—ï¼‰
        """
        unique_topics = {}
        topic_sources = defaultdict(list)

        for path in json_paths:
            if not os.path.exists(path):
                print(f"   âš ï¸  File not found: {path}")
                continue

            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            topics = data.get('topics', [])
            file_name = Path(path).stem

            for topic in topics:
                topic_name = topic.get('name', '')
                if topic_name:
                    if topic_name not in unique_topics:
                        unique_topics[topic_name] = {
                            'name': topic_name,
                            'summary': topic.get('summary', ''),
                            'keywords': topic.get('keywords', [])
                        }
                    topic_sources[topic_name].append(file_name)

        # å‡ºç¾å›æ•°ã‚’è¿½åŠ 
        for topic_name, topic_data in unique_topics.items():
            topic_data['occurrences'] = len(topic_sources[topic_name])
            topic_data['sources'] = topic_sources[topic_name]

        print(f"\nğŸ“‚ Loaded topics from {len(json_paths)} files")
        print(f"   Unique topics: {len(unique_topics)}")

        return list(unique_topics.values())

    def cluster_topics_with_llm(self, topics: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        LLMã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°

        Args:
            topics: ãƒˆãƒ”ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ

        Returns:
            ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
        """
        if len(topics) < 2:
            print("âš ï¸  Not enough topics to cluster (need at least 2)")
            return {"clusters": [], "metadata": {}}

        print(f"\nğŸ¤– Clustering {len(topics)} topics with Gemini...")

        # ãƒˆãƒ”ãƒƒã‚¯æƒ…å ±ã‚’æ•´å½¢
        topic_list = []
        for i, topic in enumerate(topics, 1):
            topic_info = f"{i}. {topic['name']}"
            if topic.get('summary'):
                topic_info += f"\n   è¦ç´„: {topic['summary']}"
            if topic.get('keywords'):
                topic_info += f"\n   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(topic['keywords'][:5])}"
            topic_info += f"\n   å‡ºç¾å›æ•°: {topic.get('occurrences', 1)}å›"
            topic_list.append(topic_info)

        topics_text = "\n\n".join(topic_list)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt = f"""ä»¥ä¸‹ã¯è¤‡æ•°ã®ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸ{len(topics)}å€‹ã®ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚
ã“ã‚Œã‚‰ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ã—ã€5-8å€‹ã®å¤§ã‚«ãƒ†ã‚´ãƒªã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªæŒ‡ç¤ºã€‘
1. æ„å‘³ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚’åŒã˜ã‚«ãƒ†ã‚´ãƒªã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
2. å„ã‚«ãƒ†ã‚´ãƒªã«åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã®åå‰ã‚’ä»˜ã‘ã‚‹
3. ãªãœãã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ã—ãŸã‹ç†ç”±ã‚’ç°¡æ½”ã«èª¬æ˜
4. ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ï¼ˆJSONã®ã¿ã€èª¬æ˜æ–‡ã¯ä¸è¦ï¼‰

ã€å‡ºåŠ›å½¢å¼ã€‘
{{
  "clusters": [
    {{
      "category_name": "ã‚«ãƒ†ã‚´ãƒªåï¼ˆä¾‹: ã‚­ãƒ£ãƒªã‚¢é–‹ç™ºï¼‰",
      "topics": ["ãƒˆãƒ”ãƒƒã‚¯1", "ãƒˆãƒ”ãƒƒã‚¯2", ...],
      "reason": "ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã®ç†ç”±ï¼ˆ1-2æ–‡ï¼‰",
      "size": ãƒˆãƒ”ãƒƒã‚¯æ•°
    }}
  ],
  "unclustered": ["ã‚«ãƒ†ã‚´ãƒªã«å«ã¾ã‚Œãªã„ãƒˆãƒ”ãƒƒã‚¯"],
  "total_categories": ã‚«ãƒ†ã‚´ãƒªç·æ•°
}}

ã€ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ã€‘
{topics_text}

ä¸Šè¨˜ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
"""

        # Gemini APIå‘¼ã³å‡ºã—
        response = self.model.generate_content(prompt)
        response_text = response.text.strip()

        # JSONæŠ½å‡º
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()

        try:
            result = json.loads(response_text)
        except json.JSONDecodeError as e:
            print(f"âŒ JSON parsing error: {e}")
            print(f"Response text: {response_text[:500]}...")
            return {"clusters": [], "metadata": {"error": str(e)}}

        # çµæœã®æ¤œè¨¼ã¨æ•´å½¢
        clusters = result.get('clusters', [])
        unclustered = result.get('unclustered', [])

        print(f"\nâœ… Clustering completed")
        print(f"   Categories found: {len(clusters)}")
        print(f"   Clustered topics: {sum(c.get('size', len(c.get('topics', []))) for c in clusters)}")
        print(f"   Unclustered topics: {len(unclustered)}")

        # ã‚¯ãƒ©ã‚¹ã‚¿è©³ç´°è¡¨ç¤º
        for i, cluster in enumerate(clusters, 1):
            print(f"\n   Category {i}: {cluster.get('category_name', 'Unknown')}")
            print(f"   Size: {cluster.get('size', len(cluster.get('topics', [])))} topics")
            print(f"   Reason: {cluster.get('reason', 'N/A')}")
            topics_in_cluster = cluster.get('topics', [])
            for topic in topics_in_cluster[:3]:  # æœ€åˆã®3ã¤ã‚’è¡¨ç¤º
                print(f"      - {topic}")
            if len(topics_in_cluster) > 3:
                print(f"      ... and {len(topics_in_cluster) - 3} more")

        return {
            'clusters': clusters,
            'unclustered': unclustered,
            'total_categories': result.get('total_categories', len(clusters)),
            'metadata': {
                'method': 'LLM-based (Gemini 2.0 Flash)',
                'total_topics': len(topics)
            }
        }

    def generate_cluster_report(
        self,
        clustering_result: Dict[str, Any],
        output_path: str = "topic_clustering_llm_report.md"
    ) -> None:
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            clustering_result: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        print(f"\nğŸ’¾ Generating clustering report: {output_path}")

        clusters = clustering_result.get('clusters', [])
        unclustered = clustering_result.get('unclustered', [])
        metadata = clustering_result.get('metadata', {})

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# LLM-Based Topic Clustering Report\n\n")
            f.write(f"**Method:** {metadata.get('method', 'LLM-based')}\n")
            f.write(f"**Total Topics Analyzed:** {metadata.get('total_topics', 'N/A')}\n\n")

            # ã‚µãƒãƒªãƒ¼
            f.write(f"## Summary\n\n")
            f.write(f"- Total categories: {len(clusters)}\n")
            f.write(f"- Clustered topics: {sum(c.get('size', len(c.get('topics', []))) for c in clusters)}\n")
            f.write(f"- Unclustered topics: {len(unclustered)}\n\n")

            # ã‚«ãƒ†ã‚´ãƒªè©³ç´°
            f.write(f"## Topic Categories\n\n")

            for i, cluster in enumerate(clusters, 1):
                category_name = cluster.get('category_name', f'Category {i}')
                topics = cluster.get('topics', [])
                reason = cluster.get('reason', 'N/A')
                size = cluster.get('size', len(topics))

                f.write(f"### {i}. {category_name}\n\n")
                f.write(f"**Size:** {size} topics\n\n")
                f.write(f"**Grouping Reason:** {reason}\n\n")
                f.write(f"**Topics:**\n")
                for topic in topics:
                    f.write(f"- {topic}\n")
                f.write("\n")

            # æœªåˆ†é¡ãƒˆãƒ”ãƒƒã‚¯
            if unclustered:
                f.write(f"## Unclustered Topics\n\n")
                f.write(f"These topics did not fit into any category:\n\n")
                for topic in unclustered:
                    f.write(f"- {topic}\n")

        print(f"âœ… Report saved: {output_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if len(sys.argv) < 2:
        print("Usage: python topic_clustering_llm.py <json_file1> <json_file2> [json_file3 ...]")
        print("Example: python topic_clustering_llm.py downloads/*_structured_enhanced.json")
        sys.exit(1)

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
    json_paths = sys.argv[1:]

    # ã‚°ãƒ­ãƒ–ãƒ‘ã‚¿ãƒ¼ãƒ³å±•é–‹
    expanded_paths = []
    for pattern in json_paths:
        from glob import glob
        matches = glob(pattern)
        if matches:
            expanded_paths.extend(matches)
        else:
            expanded_paths.append(pattern)

    json_paths = list(set(expanded_paths))

    print("=" * 70)
    print("Phase 6-3 Stage 4-1: LLM-Based Topic Clustering")
    print("=" * 70)

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
    clusterer = LLMTopicClusterer()

    # ãƒˆãƒ”ãƒƒã‚¯èª­ã¿è¾¼ã¿
    topics = clusterer.load_topics_from_json(json_paths)

    if not topics:
        print("âŒ No topics found")
        sys.exit(1)

    # LLMã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    clustering_result = clusterer.cluster_topics_with_llm(topics)

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    clusterer.generate_cluster_report(clustering_result)

    print("\n" + "=" * 70)
    print("âœ… LLM-based topic clustering completed!")
    print("   Cost: Free (Gemini 2.0 Flash)")
    print("=" * 70)


if __name__ == "__main__":
    main()
