# Project Brief: API専用 音声文字起こしシステム（超シンプル版）

## プロジェクト概要

OpenAI Whisper APIを使った**最小構成の音声文字起こしスクリプト**を構築する。

## 目的（超シンプル版）

- **動くものを最優先**: 50行のコードで完結
- **初学者でも理解可能**: 全てのコードが読める
- **エラー対応が容易**: デバッグが簡単
- **最小コスト**: Whisper APIのみ（$0.006/分）

## ターゲットユーザー

- 音声ファイルをテキスト化したい全てのユーザー
- プログラミング初学者でも使える簡単さ

## コアバリュー

1. **超シンプル**: 50行のコード、3つの関数のみ
2. **高精度**: OpenAI Whisper API（最新モデル）
3. **低コスト**: $0.36/60分音声
4. **学習容易**: 30分で理解できる

## 成功基準

- ✅ 音声ファイルを指定して実行できる
- ✅ 文字起こしが正常に動作する
- ✅ テキストファイルに保存される
- ✅ コード全体を初学者が理解できる

## 実装フェーズ

### Phase 3: 超シンプル版実装（現在）
**目標**: 50行で動くものを作る

**実装内容**:
1. コマンドライン引数で音声ファイル指定
2. OpenAI Whisper APIで文字起こし
3. テキストファイルに保存

**除外した機能**（Phase 1-2から削除）:
- ❌ 自動ファイル検出（手動指定で十分）
- ❌ 処理済みリスト管理（不要）
- ❌ 要約生成（文字起こしに集中）
- ❌ JSON/Markdown出力（TXTのみ）
- ❌ 話者分離（APIにない機能）
- ❌ メタデータ（不要）
- ❌ エラーリトライ（手動再実行で十分）

### Phase 4: 要約機能追加（Phase 3完了後）
**目標**: Gemini APIで要約生成

**実装内容**:
- Gemini APIで文字起こし結果を要約
- Markdown形式で保存
- +30行程度の追加

**前提条件**: Phase 3が動作すること

### Phase 5: 自動ファイル検出（Phase 4完了後）
**目標**: iCloud新規音声データの自動検出

**実装内容**:
- iCloudボイスメモフォルダ監視
- 新規.m4aファイル検出
- 処理済みリスト管理
- +50行程度の追加

**前提条件**: Phase 4が動作すること

## 技術スタック（Phase 3: 超シンプル版）

### 必須ライブラリのみ
```
openai                  # Whisper API
python-dotenv          # 環境変数
```

### ファイル構成
```
realtime_transcriber_benchmark_research/
├── .env                    # OPENAI_API_KEY
├── .env.example            # APIキーサンプル
├── requirements.txt        # 依存関係（2行）
├── transcribe_api.py       # メインスクリプト（50行）
└── archive_phase1_local_whisper/  # 旧実装アーカイブ
```

### OpenAI Whisper API選択理由
- セットアップ簡単（APIキーのみ）
- ローカルモデル不要
- 高速処理（API並列処理）
- 常に最新モデル

## 制約条件

- インターネット接続必須
- OpenAI APIキー必要
- ファイルサイズ上限25MB

## リスクと対策

1. **APIコスト**: 従量課金
   - 対策: 小さい音声で先にテスト
2. **ファイルサイズ制限**: 25MB
   - 対策: Phase 5で分割処理検討

## 次のステップ（Phase 3）

1. ⬜ transcribe_api.py実装（50行）
2. ⬜ requirements.txt作成（2行）
3. ⬜ .env.example作成
4. ⬜ 動作テスト

## 将来の拡張（Phase 3完了後）

**Phase 4: 要約機能**（Phase 3テスト完了後）
- Gemini API統合
- Markdown出力

**Phase 5: 自動ファイル検出**（Phase 4テスト完了後）
- iCloudフォルダ監視
- 新規ファイル自動処理
