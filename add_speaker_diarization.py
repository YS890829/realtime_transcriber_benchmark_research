#!/usr/bin/env python3
"""
æ—¢å­˜ã®æ§‹é€ åŒ–JSONã«è©±è€…è­˜åˆ¥ã‚’è¿½åŠ ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase 6-1ã®çµæœï¼ˆ_structured.jsonï¼‰ã‚’å…¥åŠ›ã¨ã—ã¦ã€è©±è€…è­˜åˆ¥ã®ã¿ã‚’å®Ÿè¡Œ
"""

import os
import sys
import json
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()


def perform_speaker_diarization(audio_path, segments):
    """è©±è€…è­˜åˆ¥ã‚’å®Ÿè¡Œ"""
    print(f"[1/3] è©±è€…è­˜åˆ¥ä¸­...")

    try:
        from pyannote.audio import Pipeline

        hf_token = os.getenv("HUGGINGFACE_TOKEN")
        if not hf_token:
            print("  Warning: HUGGINGFACE_TOKEN not found.")
            return fallback_speaker_assignment(segments)

        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=hf_token
        )

        diarization = pipeline(audio_path)

        # è©±è€…æƒ…å ±é›†è¨ˆ
        speakers_info = {}
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            if speaker not in speakers_info:
                speakers_info[speaker] = {
                    "id": speaker,
                    "label": f"Speaker {len(speakers_info) + 1}",
                    "total_duration": 0.0
                }
            speakers_info[speaker]["total_duration"] += turn.duration

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«è©±è€…å‰²ã‚Šå½“ã¦
        segments_with_speaker = []
        for seg in segments:
            seg_start = seg["start"]
            seg_end = seg["end"]

            max_overlap = 0.0
            assigned_speaker = "SPEAKER_00"

            for turn, _, speaker in diarization.itertracks(yield_label=True):
                overlap_start = max(seg_start, turn.start)
                overlap_end = min(seg_end, turn.end)
                overlap = max(0, overlap_end - overlap_start)

                if overlap > max_overlap:
                    max_overlap = overlap
                    assigned_speaker = speaker

            seg_copy = seg.copy()
            seg_copy["speaker"] = assigned_speaker
            segments_with_speaker.append(seg_copy)

        # è©±è€…ãƒªã‚¹ãƒˆä½œæˆ
        speakers_list = []
        total_duration = sum(s["total_duration"] for s in speakers_info.values())

        for speaker_id, info in speakers_info.items():
            speakers_list.append({
                "id": speaker_id,
                "label": info["label"],
                "total_duration": round(info["total_duration"], 2),
                "speaking_percentage": round((info["total_duration"] / total_duration) * 100, 1) if total_duration > 0 else 0
            })

        print(f"  Detected {len(speakers_list)} speakers")

        return {
            "speakers": speakers_list,
            "segments_with_speaker": segments_with_speaker
        }

    except Exception as e:
        print(f"  Error: {e}")
        return fallback_speaker_assignment(segments)


def fallback_speaker_assignment(segments):
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ä¸€è©±è€…"""
    total_duration = sum(seg["end"] - seg["start"] for seg in segments)

    segments_with_speaker = []
    for seg in segments:
        seg_copy = seg.copy()
        seg_copy["speaker"] = "SPEAKER_00"
        segments_with_speaker.append(seg_copy)

    return {
        "speakers": [{
            "id": "SPEAKER_00",
            "label": "Speaker 1",
            "total_duration": round(total_duration, 2),
            "speaking_percentage": 100.0
        }],
        "segments_with_speaker": segments_with_speaker
    }


def extract_topics_and_entities(full_text):
    """ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º"""
    print(f"[2/3] ãƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºä¸­...")

    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    model = genai.GenerativeModel("gemini-2.0-flash-exp")

    prompt = f"""
ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

{{
  "topics": [
    {{
      "id": "topic_1",
      "name": "ãƒˆãƒ”ãƒƒã‚¯å",
      "summary": "ãƒˆãƒ”ãƒƒã‚¯ã®è¦ç´„ï¼ˆ1-2æ–‡ï¼‰",
      "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"]
    }}
  ],
  "entities": {{
    "people": ["äººå1", "äººå2"],
    "organizations": ["çµ„ç¹”å1", "çµ„ç¹”å2"],
    "dates": ["æ—¥ä»˜è¡¨ç¾1", "æ—¥ä»˜è¡¨ç¾2"],
    "action_items": ["ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2"]
  }}
}}

æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ:
{full_text}
"""

    try:
        response = model.generate_content(prompt)
        response_text = response.text.strip()

        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()

        result = json.loads(response_text)

        print(f"  Extracted {len(result.get('topics', []))} topics")
        print(f"  Found {len(result.get('entities', {}).get('people', []))} people")

        return result

    except Exception as e:
        print(f"  Error: {e}")
        return {
            "topics": [],
            "entities": {"people": [], "organizations": [], "dates": [], "action_items": []}
        }


def assign_topics_to_segments(segments, topics):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ãƒˆãƒ”ãƒƒã‚¯å‰²ã‚Šå½“ã¦"""
    segments_enhanced = []

    for seg in segments:
        seg_text = seg["text"]
        assigned_topics = []

        for topic in topics:
            keywords = topic.get("keywords", [])
            if any(keyword in seg_text for keyword in keywords):
                assigned_topics.append(topic["id"])

        seg_copy = seg.copy()
        seg_copy["topics"] = assigned_topics if assigned_topics else []
        segments_enhanced.append(seg_copy)

    return segments_enhanced


def generate_enhanced_summary(full_text, topics, entities, speakers):
    """æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸè¦ç´„"""
    print(f"[3/3] è¦ç´„ç”Ÿæˆä¸­...")

    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    model = genai.GenerativeModel("gemini-2.0-flash-exp")

    speakers_info = "\n".join([
        f"- {s['label']}: {s['speaking_percentage']}% ({s['total_duration']}ç§’)"
        for s in speakers
    ])

    topics_info = "\n".join([
        f"- {t['name']}: {t['summary']}"
        for t in topics
    ])

    entities_info = f"""
- äººç‰©: {', '.join(entities.get('people', []))}
- çµ„ç¹”: {', '.join(entities.get('organizations', []))}
- æ—¥ä»˜: {', '.join(entities.get('dates', []))}
- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {', '.join(entities.get('action_items', []))}
"""

    prompt = f"""
ä»¥ä¸‹ã®æƒ…å ±ã‚’å…ƒã«ã€ä¼šè©±ã®è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€è©±è€…æƒ…å ±ã€‘
{speakers_info}

ã€ãƒˆãƒ”ãƒƒã‚¯ã€‘
{topics_info}

ã€æŠ½å‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã€‘
{entities_info}

ã€å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã€‘
{full_text[:5000]}...

ä»¥ä¸‹ã®å½¢å¼ã§è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

# ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
ï¼ˆ2-3æ–‡ã§å…¨ä½“ã®æ¦‚è¦ï¼‰

# ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ
- ãƒã‚¤ãƒ³ãƒˆ1
- ãƒã‚¤ãƒ³ãƒˆ2
- ãƒã‚¤ãƒ³ãƒˆ3

# è©³ç´°ã‚µãƒãƒªãƒ¼
ï¼ˆå„ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ï¼‰
"""

    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"  Error: {e}")
        return "è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"


def main():
    if len(sys.argv) < 3:
        print("Usage: python add_speaker_diarization.py <audio_file> <structured_json>")
        sys.exit(1)

    audio_path = sys.argv[1]
    json_path = sys.argv[2]

    if not os.path.exists(audio_path):
        print(f"Error: Audio file not found: {audio_path}")
        sys.exit(1)

    if not os.path.exists(json_path):
        print(f"Error: JSON file not found: {json_path}")
        sys.exit(1)

    print(f"ğŸ™ï¸ Phase 6-2å‡¦ç†é–‹å§‹")
    print(f"  éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {audio_path}")
    print(f"  å…¥åŠ›JSON: {json_path}")

    # æ—¢å­˜ã®JSONã‚’èª­ã¿è¾¼ã¿
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # è©±è€…è­˜åˆ¥å®Ÿè¡Œ
    diarization_result = perform_speaker_diarization(audio_path, data["segments"])

    # ãƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º
    topics_result = extract_topics_and_entities(data["full_text"])

    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ãƒˆãƒ”ãƒƒã‚¯å‰²ã‚Šå½“ã¦
    segments_enhanced = assign_topics_to_segments(
        diarization_result["segments_with_speaker"],
        topics_result["topics"]
    )

    # æ§‹é€ åŒ–è¦ç´„ç”Ÿæˆ
    summary = generate_enhanced_summary(
        data["full_text"],
        topics_result["topics"],
        topics_result["entities"],
        diarization_result["speakers"]
    )

    # æ‹¡å¼µJSONã‚’ä½œæˆ
    enhanced_data = data.copy()
    enhanced_data["speakers"] = diarization_result["speakers"]
    enhanced_data["topics"] = topics_result["topics"]
    enhanced_data["entities"] = topics_result["entities"]
    enhanced_data["segments"] = segments_enhanced
    enhanced_data["summary"] = summary

    # å‡ºåŠ›
    output_path = Path(audio_path).with_suffix('').name + "_enhanced.json"
    output_dir = Path(audio_path).parent
    output_file = output_dir / output_path

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(enhanced_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… JSONä¿å­˜å®Œäº†: {output_file}")

    print(f"\nğŸ“Š å‡¦ç†çµ±è¨ˆ:")
    print(f"  è©±è€…æ•°: {len(enhanced_data['speakers'])}")
    print(f"  ãƒˆãƒ”ãƒƒã‚¯æ•°: {len(enhanced_data['topics'])}")
    print(f"  ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: äººç‰©{len(enhanced_data['entities'].get('people', []))}å")

    print(f"\nğŸ‰ å®Œäº†!")


if __name__ == "__main__":
    main()
