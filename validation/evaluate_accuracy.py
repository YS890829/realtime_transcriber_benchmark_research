#!/usr/bin/env python3
"""
è‡ªå‹•è©•ä¾¡: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®šé‡æ¯”è¼ƒ

è‡ªå‹•è¨ˆç®—å¯èƒ½ãªæŒ‡æ¨™ã§ç²¾åº¦ã‚’æ¯”è¼ƒ
"""

import json
import sys
import os
from pathlib import Path
from datetime import datetime
import re

def extract_keywords(text):
    """
    é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆå›ºæœ‰åè©ã€æ•°å­—ã€å°‚é–€ç”¨èªï¼‰
    ç°¡æ˜“ç‰ˆ: ã‚«ã‚¿ã‚«ãƒŠèªã€æ•°å­—ã€é•·ã„å˜èªã‚’æŠ½å‡º
    """
    keywords = set()

    # ã‚«ã‚¿ã‚«ãƒŠèªï¼ˆ3æ–‡å­—ä»¥ä¸Šï¼‰
    katakana_words = re.findall(r'[ã‚¡-ãƒ´ãƒ¼]{3,}', text)
    keywords.update(katakana_words)

    # æ•°å­—ã‚’å«ã‚€å˜èª
    number_words = re.findall(r'\d+[å¹´æœˆæ—¥å††ä¸‡å„„å…†%å°ä»¶äººç¤¾]', text)
    keywords.update(number_words)

    # é•·ã„æ¼¢å­—èªï¼ˆ4æ–‡å­—ä»¥ä¸Šï¼‰
    kanji_words = re.findall(r'[ä¸€-é¾¯]{4,}', text)
    keywords.update(kanji_words)

    return keywords

def calculate_keyword_retention(original_keywords, summary_keywords):
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¿æŒç‡ã‚’è¨ˆç®—
    """
    if not original_keywords:
        return 0.0

    retained = original_keywords & summary_keywords
    retention_rate = len(retained) / len(original_keywords)

    return retention_rate

def calculate_info_density(filename):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«åã®æƒ…å ±å¯†åº¦ã‚’è¨ˆç®—
    æƒ…å ±å˜ä½: æ—¥ä»˜ã€ä¼šè©±ç¨®é¡ã€ãƒˆãƒ”ãƒƒã‚¯ã€äººåãªã©
    """
    info_units = 0

    # æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³
    if re.search(r'\d{1,2}[-/]\d{1,2}', filename):
        info_units += 1

    # ä¼šè©±ç¨®é¡
    types = ['é¢è«‡', 'ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°', 'ä¼šè©±', 'ç‹¬ç™½', 'ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼', 'æ‰“ã¡åˆã‚ã›']
    for t in types:
        if t in filename:
            info_units += 1
            break

    # ãƒˆãƒ”ãƒƒã‚¯æ•°ï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—ã§æ¨å®šï¼‰
    topic_separators = filename.count('ã¨') + filename.count('ãƒ»') + filename.count('ã€')
    info_units += min(topic_separators + 1, 3)  # æœ€å¤§3ãƒˆãƒ”ãƒƒã‚¯

    # äººåï¼ˆSugimotoãªã©ï¼‰
    if 'Sugimoto' in filename or 'æ‰æœ¬' in filename:
        info_units += 1

    return info_units

def evaluate_baseline(baseline_file):
    """
    ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    """
    with open(baseline_file, 'r', encoding='utf-8') as f:
        baseline = json.load(f)

    # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    original_text = "\n".join([seg['text'] for seg in baseline['segments']])
    original_keywords = extract_keywords(original_text)

    # è¦ç´„ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    summary_text = "\n".join([seg['text'] for seg in baseline['summarized_segments']])
    summary_keywords = extract_keywords(summary_text)

    # æŒ‡æ¨™è¨ˆç®—
    metrics = {
        'execution_time': baseline['metadata']['execution_time_seconds'],
        'summary_length': baseline['statistics']['summary_chars'],
        'original_length': baseline['statistics']['total_chars'],
        'compression_ratio': baseline['statistics']['summary_chars'] / baseline['statistics']['total_chars'],
        'topic_count': baseline['statistics']['topic_count'],
        'topics': baseline['topics'],
        'filename': baseline['generated_filename'],
        'filename_length': baseline['statistics']['filename_length'],
        'filename_info_density': calculate_info_density(baseline['generated_filename']),
        'original_keywords_count': len(original_keywords),
        'summary_keywords_count': len(summary_keywords),
        'keyword_retention_rate': calculate_keyword_retention(original_keywords, summary_keywords)
    }

    return metrics

def evaluate_new_pipeline(new_pipeline_file):
    """
    æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—

    æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ _structured_final.json ã‚’æƒ³å®š
    """
    with open(new_pipeline_file, 'r', encoding='utf-8') as f:
        new_data = json.load(f)

    # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    original_text = "\n".join([seg['text'] for seg in new_data['segments']])
    original_keywords = extract_keywords(original_text)

    # è¦ç´„ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    summary_text = "\n".join([seg['text'] for seg in new_data['summarized_segments']])
    summary_keywords = extract_keywords(summary_text)

    # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°ã‚’è¨ˆç®—
    entities = new_data.get('topics_entities', {}).get('entities', {})
    entity_count = sum(len(v) for v in entities.values())

    # è©±è€…æƒ…å ±
    speaker_info = new_data['metadata'].get('speaker_inference', {})

    # ãƒ•ã‚¡ã‚¤ãƒ«åæƒ…å ±
    optimal_filename_info = new_data['metadata'].get('optimal_filename', {})
    generated_filename = optimal_filename_info.get('filename', 'N/A')

    # æŒ‡æ¨™è¨ˆç®—
    metrics = {
        'speaker_identification': {
            'sugimoto_segments': speaker_info.get('sugimoto_segments', 0),
            'other_segments': speaker_info.get('other_segments', 0),
            'confidence': speaker_info.get('result', {}).get('confidence', 'unknown')
        },
        'summary_length': sum(len(seg['text']) for seg in new_data['summarized_segments']),
        'original_length': sum(len(seg['text']) for seg in new_data['segments']),
        'compression_ratio': sum(len(seg['text']) for seg in new_data['summarized_segments']) / sum(len(seg['text']) for seg in new_data['segments']),
        'topic_count': len(new_data.get('topics_entities', {}).get('topics', [])),
        'topics': new_data.get('topics_entities', {}).get('topics', []),
        'entity_count': entity_count,
        'entities_by_category': {k: len(v) for k, v in entities.items()},
        'filename': generated_filename,
        'filename_length': len(generated_filename),
        'filename_info_density': calculate_info_density(generated_filename),
        'original_keywords_count': len(original_keywords),
        'summary_keywords_count': len(summary_keywords),
        'keyword_retention_rate': calculate_keyword_retention(original_keywords, summary_keywords)
    }

    return metrics

def compare_metrics(baseline_metrics, new_metrics):
    """
    2ã¤ã®æŒ‡æ¨™ã‚’æ¯”è¼ƒã—ã€æ”¹å–„ç‡ã‚’è¨ˆç®—
    """
    comparison = {
        'keyword_retention_improvement': (
            new_metrics['keyword_retention_rate'] - baseline_metrics['keyword_retention_rate']
        ),
        'topic_coverage_improvement': (
            (new_metrics['topic_count'] - baseline_metrics['topic_count']) / baseline_metrics['topic_count']
            if baseline_metrics['topic_count'] > 0 else 0
        ),
        'filename_info_density_improvement': (
            new_metrics['filename_info_density'] / baseline_metrics['filename_info_density']
            if baseline_metrics['filename_info_density'] > 0 else 0
        ),
        'compression_improvement': (
            baseline_metrics['compression_ratio'] - new_metrics['compression_ratio']
        ),
        'entity_extraction_added': new_metrics['entity_count']  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ã¯ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºãªã—
    }

    return comparison

def generate_report(baseline_metrics, new_metrics, comparison, output_file):
    """
    è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    """
    report = {
        'metadata': {
            'evaluation_date': datetime.now().isoformat(),
            'evaluation_method': 'automatic_metrics'
        },
        'baseline': baseline_metrics,
        'new_pipeline': new_metrics,
        'comparison': comparison,
        'summary': {
            'key_improvements': [],
            'metrics_summary': {}
        }
    }

    # ä¸»è¦ãªæ”¹å–„ç‚¹ã‚’æŠ½å‡º
    if comparison['keyword_retention_improvement'] > 0.1:
        report['summary']['key_improvements'].append(
            f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¿æŒç‡ãŒ{comparison['keyword_retention_improvement']*100:.1f}%å‘ä¸Š"
        )

    if comparison['topic_coverage_improvement'] > 0.3:
        report['summary']['key_improvements'].append(
            f"ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºãŒ{comparison['topic_coverage_improvement']*100:.1f}%æ”¹å–„"
        )

    if comparison['filename_info_density_improvement'] > 1.5:
        report['summary']['key_improvements'].append(
            f"ãƒ•ã‚¡ã‚¤ãƒ«åã®æƒ…å ±å¯†åº¦ãŒ{comparison['filename_info_density_improvement']:.1f}å€å‘ä¸Š"
        )

    report['summary']['metrics_summary'] = {
        'baseline_topics': baseline_metrics['topic_count'],
        'new_pipeline_topics': new_metrics['topic_count'],
        'new_pipeline_entities': new_metrics['entity_count'],
        'baseline_filename': baseline_metrics['filename'],
        'new_pipeline_filename': new_metrics['filename']
    }

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“Š Evaluation Report saved to: {output_file}")

    return report

def main():
    if len(sys.argv) < 3:
        print("Usage: python evaluate_accuracy.py <baseline_result.json> <new_pipeline_result.json>")
        sys.exit(1)

    baseline_file = sys.argv[1]
    new_pipeline_file = sys.argv[2]

    if not os.path.exists(baseline_file):
        print(f"Error: Baseline file not found: {baseline_file}")
        sys.exit(1)

    if not os.path.exists(new_pipeline_file):
        print(f"Error: New pipeline file not found: {new_pipeline_file}")
        sys.exit(1)

    print("="*80)
    print("ğŸ“Š Automatic Evaluation: Baseline vs New Pipeline")
    print("="*80)

    print("\nğŸ” Evaluating baseline...")
    baseline_metrics = evaluate_baseline(baseline_file)

    print("ğŸ” Evaluating new pipeline...")
    new_metrics = evaluate_new_pipeline(new_pipeline_file)

    print("\nğŸ” Comparing metrics...")
    comparison = compare_metrics(baseline_metrics, new_metrics)

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    output_file = "evaluation_report_automatic.json"
    report = generate_report(baseline_metrics, new_metrics, comparison, output_file)

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ“ˆ Evaluation Summary")
    print("="*80)

    print(f"\nã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã€‘")
    print(f"  ãƒˆãƒ”ãƒƒã‚¯æ•°: {baseline_metrics['topic_count']}")
    print(f"  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¿æŒç‡: {baseline_metrics['keyword_retention_rate']*100:.1f}%")
    print(f"  ãƒ•ã‚¡ã‚¤ãƒ«å: {baseline_metrics['filename']}")
    print(f"  æƒ…å ±å¯†åº¦: {baseline_metrics['filename_info_density']}")

    print(f"\nã€æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‘")
    print(f"  è©±è€…è­˜åˆ¥: {new_metrics['speaker_identification']['confidence']}")
    print(f"  ãƒˆãƒ”ãƒƒã‚¯æ•°: {new_metrics['topic_count']}")
    print(f"  ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°: {new_metrics['entity_count']}")
    print(f"  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¿æŒç‡: {new_metrics['keyword_retention_rate']*100:.1f}%")
    print(f"  ãƒ•ã‚¡ã‚¤ãƒ«å: {new_metrics['filename']}")
    print(f"  æƒ…å ±å¯†åº¦: {new_metrics['filename_info_density']}")

    print(f"\nã€æ”¹å–„ç‚¹ã€‘")
    for improvement in report['summary']['key_improvements']:
        print(f"  âœ… {improvement}")

    print("\nâœ… Automatic evaluation complete!")

if __name__ == '__main__':
    main()
