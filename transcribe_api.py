#!/usr/bin/env python3
"""
è¶…ã‚·ãƒ³ãƒ—ãƒ«æ–‡å­—èµ·ã“ã—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ä½¿ã„æ–¹: python transcribe_api.py <éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>
"""

import os
import sys
from openai import OpenAI
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

def transcribe_audio(file_path):
    """
    OpenAI Whisper APIã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—

    å¼•æ•°:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆ.m4a, .mp3, .wavç­‰ï¼‰

    æˆ»ã‚Šå€¤:
        æ–‡å­—èµ·ã“ã—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ–‡å­—åˆ—ï¼‰
    """
    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
    with open(file_path, "rb") as audio_file:
        # Whisper APIã§æ–‡å­—èµ·ã“ã—
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="ja"  # æ—¥æœ¬èªæŒ‡å®š
        )

    return response.text

def save_text(text, output_path):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

    å¼•æ•°:
        text: ä¿å­˜ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(text)
    print(f"âœ… ä¿å­˜å®Œäº†: {output_path}")

def main():
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãƒã‚§ãƒƒã‚¯
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: python transcribe_api.py <éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>")
        sys.exit(1)

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å–å¾—
    audio_path = sys.argv[1]

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(audio_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_path}")
        sys.exit(1)

    print(f"ğŸ™ï¸ æ–‡å­—èµ·ã“ã—é–‹å§‹: {audio_path}")

    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
    text = transcribe_audio(audio_path)

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆ.txtï¼‰
    output_path = audio_path.rsplit(".", 1)[0] + "_transcription.txt"

    # ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜
    save_text(text, output_path)

    print("ğŸ‰ å®Œäº†!")

if __name__ == "__main__":
    main()
