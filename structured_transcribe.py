#!/usr/bin/env python3
"""
Structured Transcription with Metadata (Phase 7 Stage 7-1)
ä½¿ã„æ–¹: python structured_transcribe.py <éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>
æ©Ÿèƒ½: Gemini Audio API (è©±è€…è­˜åˆ¥ä»˜ã) + JSONæ§‹é€ åŒ–
æ³¨æ„: Word-level/Segment-level timestampsã¯éå¯¾å¿œï¼ˆGeminiã®åˆ¶ç´„ï¼‰
"""

import os
import sys
import json
import subprocess
import time
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
import google.generativeai as genai

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# Gemini API Keyé¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡æ–™æ ï¼‰
USE_PAID_TIER = os.getenv("USE_PAID_TIER", "false").lower() == "true"
if USE_PAID_TIER:
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_PAID")
    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY_PAID not set but USE_PAID_TIER=true")
    print("â„¹ï¸  Using PAID tier API key")
else:
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_FREE")
    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY_FREE not set")
    print("â„¹ï¸  Using FREE tier API key")

# Gemini API inline file size limit (20MB)
MAX_FILE_SIZE = 20 * 1024 * 1024  # 20MB in bytes


def split_audio_file(file_path, chunk_duration=600):
    """
    Split large audio file into chunks using ffmpeg
    """
    file_path = Path(file_path)
    output_dir = file_path.parent / f"{file_path.stem}_chunks"
    output_dir.mkdir(exist_ok=True)

    output_pattern = str(output_dir / f"chunk_%03d{file_path.suffix}")

    cmd = [
        'ffmpeg',
        '-i', str(file_path),
        '-f', 'segment',
        '-segment_time', str(chunk_duration),
        '-c', 'copy',
        output_pattern
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        raise Exception(f"ffmpeg failed: {result.stderr}")

    chunks = sorted(output_dir.glob(f"chunk_*{file_path.suffix}"))
    return chunks


def transcribe_audio_with_gemini(file_path):
    """
    Gemini Audio APIã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆè©±è€…è­˜åˆ¥ä»˜ãï¼‰

    æˆ»ã‚Šå€¤:
        dict: {
            "text": å…¨æ–‡,
            "segments": [ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ with speaker],
            "words": None,  # Geminiã¯éå¯¾å¿œ
            "speakers": [è©±è€…ãƒªã‚¹ãƒˆ]
        }
    """
    genai.configure(api_key=GEMINI_API_KEY)
    # Use Gemini 2.5 Flash
    model = genai.GenerativeModel("gemini-2.5-flash")

    file_size = os.path.getsize(file_path)
    file_path_obj = Path(file_path)
    mime_type = f"audio/{file_path_obj.suffix[1:]}" if file_path_obj.suffix else "audio/mpeg"

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ20MBè¶…éã®å ´åˆã¯åˆ†å‰²ï¼‰
    if file_size > MAX_FILE_SIZE:
        print(f"  File size: {file_size / 1024 / 1024:.1f}MB (exceeds 20MB limit)")
        print(f"  Splitting into chunks...")

        chunks = split_audio_file(file_path)
        print(f"  Created {len(chunks)} chunks")

        # å„ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—
        all_segments = []
        all_speakers = {}
        full_text_parts = []
        segment_id_offset = 0

        for i, chunk_path in enumerate(chunks, 1):
            print(f"  Transcribing chunk {i}/{len(chunks)}...", end='\r')

            # Rate limiting: 2 RPM = 30 seconds per request
            if i > 1:
                time.sleep(30)

            with open(chunk_path, "rb") as audio_file:
                audio_bytes = audio_file.read()

            prompt = """ã“ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
{
  "segments": [
    {
      "speaker": "Speaker 1",
      "text": "ç™ºè¨€å†…å®¹",
      "timestamp": "MM:SS"
    }
  ]
}

ã€è¦ä»¶ã€‘
1. è©±è€…ã‚’è­˜åˆ¥ã—ã€Speaker 1, Speaker 2ãªã©ã®ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸
2. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã«è©±è€…ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜è¼‰
3. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯MM:SSå½¢å¼ã§æ¨å®š
4. æ—¥æœ¬èªã®æ–‡å­—èµ·ã“ã—"""

            response = model.generate_content(
                [prompt, {"mime_type": mime_type, "data": audio_bytes}],
                generation_config={
                    "response_mime_type": "application/json"
                }
            )

            # JSONãƒ‘ãƒ¼ã‚¹
            try:
                chunk_data = json.loads(response.text)

                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ ï¼ˆIDèª¿æ•´ï¼‰
                for seg in chunk_data.get("segments", []):
                    segment = {
                        "id": len(all_segments) + 1,
                        "speaker": seg.get("speaker", "Unknown"),
                        "text": seg.get("text", ""),
                        "timestamp": seg.get("timestamp", "00:00")
                    }
                    all_segments.append(segment)

                    # è©±è€…ã‚«ã‚¦ãƒ³ãƒˆ
                    speaker = segment["speaker"]
                    if speaker not in all_speakers:
                        all_speakers[speaker] = 0
                    all_speakers[speaker] += 1

                # ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ 
                full_text_parts.append(" ".join([s.get("text", "") for s in chunk_data.get("segments", [])]))

            except json.JSONDecodeError as e:
                print(f"\n  Warning: JSON parse error in chunk {i}: {e}")
                print(f"  Attempting to repair...")

                # JSONä¿®å¾©è©¦è¡Œ
                try:
                    text = response.text
                    last_complete = text.rfind('},')
                    if last_complete > 0:
                        repaired = text[:last_complete + 1] + '\n  ]\n}'
                        chunk_data = json.loads(repaired)

                        for seg in chunk_data.get("segments", []):
                            segment = {
                                "id": len(all_segments) + 1,
                                "speaker": seg.get("speaker", "Unknown"),
                                "text": seg.get("text", ""),
                                "timestamp": seg.get("timestamp", "00:00")
                            }
                            all_segments.append(segment)

                            speaker = segment["speaker"]
                            if speaker not in all_speakers:
                                all_speakers[speaker] = 0
                            all_speakers[speaker] += 1

                        full_text_parts.append(" ".join([s.get("text", "") for s in chunk_data.get("segments", [])]))
                        print(f"  âœ“ Chunk {i} JSON repaired successfully.")
                    else:
                        raise ValueError("Cannot repair")
                except Exception:
                    # ä¿®å¾©å¤±æ•—æ™‚ã¯ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
                    full_text_parts.append(response.text)

        print()  # æ”¹è¡Œ

        # ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
        for chunk in chunks:
            chunk.unlink()
        chunks[0].parent.rmdir()

        # è©±è€…ãƒªã‚¹ãƒˆç”Ÿæˆ
        speakers = [
            {"id": speaker, "segment_count": count}
            for speaker, count in all_speakers.items()
        ]

        return {
            "text": "\n\n".join(full_text_parts),
            "segments": all_segments,
            "words": None,  # Geminiã¯éå¯¾å¿œ
            "speakers": speakers
        }

    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ20MBä»¥ä¸‹ã®å ´åˆã¯é€šå¸¸å‡¦ç†
        with open(file_path, "rb") as audio_file:
            audio_bytes = audio_file.read()

        prompt = """ã“ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
{
  "segments": [
    {
      "speaker": "Speaker 1",
      "text": "ç™ºè¨€å†…å®¹",
      "timestamp": "MM:SS"
    }
  ]
}

ã€è¦ä»¶ã€‘
1. è©±è€…ã‚’è­˜åˆ¥ã—ã€Speaker 1, Speaker 2ãªã©ã®ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸
2. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã«è©±è€…ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜è¼‰
3. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯MM:SSå½¢å¼ã§æ¨å®š
4. æ—¥æœ¬èªã®æ–‡å­—èµ·ã“ã—"""

        response = model.generate_content(
            [prompt, {"mime_type": mime_type, "data": audio_bytes}],
            generation_config={
                "response_mime_type": "application/json"
            }
        )

        # JSONãƒ‘ãƒ¼ã‚¹
        try:
            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼šfinish_reasonã‚’ãƒã‚§ãƒƒã‚¯
            if not response.text:
                print(f"âš ï¸ Gemini API response error: finish_reason={response.candidates[0].finish_reason}")
                print(f"Safety ratings: {response.candidates[0].safety_ratings}")
                raise ValueError(f"Gemini blocked response: finish_reason={response.candidates[0].finish_reason}")

            data = json.loads(response.text)

            segments = []
            speakers_dict = {}

            for i, seg in enumerate(data.get("segments", []), 1):
                speaker = seg.get("speaker", "Unknown")
                segment = {
                    "id": i,
                    "speaker": speaker,
                    "text": seg.get("text", ""),
                    "timestamp": seg.get("timestamp", "00:00")
                }
                segments.append(segment)

                # è©±è€…ã‚«ã‚¦ãƒ³ãƒˆ
                if speaker not in speakers_dict:
                    speakers_dict[speaker] = 0
                speakers_dict[speaker] += 1

            # è©±è€…ãƒªã‚¹ãƒˆç”Ÿæˆ
            speakers = [
                {"id": speaker, "segment_count": count}
                for speaker, count in speakers_dict.items()
            ]

            # å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            full_text = " ".join([s.get("text", "") for s in data.get("segments", [])])

            return {
                "text": full_text,
                "segments": segments,
                "words": None,  # Geminiã¯éå¯¾å¿œ
                "speakers": speakers
            }

        except json.JSONDecodeError as e:
            print(f"  Warning: JSON parse error: {e}")
            print(f"  Attempting to repair truncated JSON...")

            # JSONä¿®å¾©è©¦è¡Œ: æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒä¸å®Œå…¨ãªå ´åˆã€ãã‚Œã‚’å‰Šé™¤ã—ã¦é–‰ã˜ã‚‹
            try:
                text = response.text
                # æœ€å¾Œã®å®Œå…¨ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã‚‹
                last_complete = text.rfind('},')
                if last_complete > 0:
                    # ãã“ã¾ã§ã‚’å–ã‚Šã€é…åˆ—ã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é–‰ã˜ã‚‹
                    repaired = text[:last_complete + 1] + '\n  ]\n}'
                    data = json.loads(repaired)

                    segments = []
                    speakers_dict = {}

                    for i, seg in enumerate(data.get("segments", []), 1):
                        speaker = seg.get("speaker", "Unknown")
                        segment = {
                            "id": i,
                            "speaker": speaker,
                            "text": seg.get("text", ""),
                            "timestamp": seg.get("timestamp", "00:00")
                        }
                        segments.append(segment)

                        if speaker not in speakers_dict:
                            speakers_dict[speaker] = 0
                        speakers_dict[speaker] += 1

                    speakers = [
                        {"id": speaker, "segment_count": count}
                        for speaker, count in speakers_dict.items()
                    ]

                    full_text = " ".join([s.get("text", "") for s in data.get("segments", [])])

                    print(f"  âœ“ JSON repaired successfully. Recovered {len(segments)} segments.")

                    return {
                        "text": full_text,
                        "segments": segments,
                        "words": None,
                        "speakers": speakers
                    }
                else:
                    raise ValueError("Cannot find valid segment boundary")

            except Exception as repair_error:
                print(f"  Warning: JSON repair failed: {repair_error}")
                print(f"  Response preview: {response.text[:200]}...")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return {
                    "text": response.text,
                    "segments": [],
                    "words": None,
                    "speakers": []
                }


def summarize_text(text):
    """
    Gemini APIã§ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ï¼ˆè©³ç´°ãƒ­ã‚°ä»˜ãï¼‰
    å¤±æ•—æ™‚ã¯Noneã‚’è¿”ã™ï¼ˆä¾‹å¤–ã‚’ä¸Šã’ãªã„ï¼‰
    """
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel("gemini-2.5-flash")

    prompt = f"""ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ã€è¦ç´„å½¢å¼ã€‘
1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆ2-3è¡Œï¼‰
2. ä¸»è¦ãƒã‚¤ãƒ³ãƒˆï¼ˆç®‡æ¡æ›¸ãã€3-5é …ç›®ï¼‰
3. è©³ç´°ã‚µãƒãƒªãƒ¼ï¼ˆæ®µè½å½¢å¼ï¼‰

ã€æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã€‘
{text}
"""

    # ãƒ­ã‚°: è¦ç´„ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±
    print(f"  [è¦ç´„API] ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text)}æ–‡å­—", flush=True)
    print(f"  [è¦ç´„API] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(prompt)}æ–‡å­—", flush=True)
    print(f"  [è¦ç´„API] APIå‘¼ã³å‡ºã—é–‹å§‹...", flush=True)

    try:
        response = model.generate_content(prompt)

        # ãƒ­ã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°
        print(f"  [è¦ç´„API] APIå‘¼ã³å‡ºã—å®Œäº†", flush=True)
        print(f"  [è¦ç´„API] Response type: {type(response)}", flush=True)

        if hasattr(response, 'candidates'):
            candidates_count = len(response.candidates) if response.candidates else 0
            print(f"  [è¦ç´„API] Candidates count: {candidates_count}", flush=True)

            if not response.candidates or candidates_count == 0:
                print(f"  [è¦ç´„API] âŒ ã‚¨ãƒ©ãƒ¼: response.candidates is empty", flush=True)

                # prompt_feedbackã‚’ç¢ºèª
                if hasattr(response, 'prompt_feedback'):
                    feedback = response.prompt_feedback
                    print(f"  [è¦ç´„API] prompt_feedback: {feedback}", flush=True)

                    if hasattr(feedback, 'block_reason'):
                        print(f"  [è¦ç´„API] block_reason: {feedback.block_reason}", flush=True)

                    if hasattr(feedback, 'safety_ratings'):
                        print(f"  [è¦ç´„API] safety_ratings:", flush=True)
                        for rating in feedback.safety_ratings:
                            print(f"    - {rating}", flush=True)

                print(f"  [è¦ç´„API] âš ï¸  è¦ç´„ç”Ÿæˆå¤±æ•—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: summary=nullï¼‰", flush=True)
                return None

            # æ­£å¸¸ãªå ´åˆã®ãƒ­ã‚°
            candidate = response.candidates[0]
            print(f"  [è¦ç´„API] finish_reason: {candidate.finish_reason if hasattr(candidate, 'finish_reason') else 'N/A'}", flush=True)

            if hasattr(candidate, 'safety_ratings'):
                print(f"  [è¦ç´„API] safety_ratings:", flush=True)
                for rating in candidate.safety_ratings:
                    print(f"    - {rating}", flush=True)

            print(f"  [è¦ç´„API] âœ… è¦ç´„ç”ŸæˆæˆåŠŸ (é•·ã•: {len(response.text)}æ–‡å­—)", flush=True)

        return response.text

    except Exception as e:
        print(f"  [è¦ç´„API] âŒ Exception: {type(e).__name__}: {e}", flush=True)
        print(f"  [è¦ç´„API] âš ï¸  è¦ç´„ç”Ÿæˆå¤±æ•—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: summary=nullï¼‰", flush=True)
        import traceback
        traceback.print_exc()
        return None



def extract_file_metadata(audio_path):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    """
    path = Path(audio_path)
    stat = path.stat()

    # ffprobeã§éŸ³å£°é•·ã‚’å–å¾—
    try:
        cmd = [
            'ffprobe',
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        duration = float(result.stdout.strip()) if result.returncode == 0 else None
    except:
        duration = None

    return {
        "file_name": path.name,
        "file_size_bytes": stat.st_size,
        "format": path.suffix[1:] if path.suffix else None,
        "recorded_at": datetime.fromtimestamp(stat.st_ctime).isoformat(),
        "duration_seconds": duration
    }


def extract_transcription_metadata(text, segments):
    """
    æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    """
    char_count = len(text)
    word_count = len(text.split())
    sentence_count = text.count('ã€‚') + text.count('.') + text.count('!') + text.count('ï¼Ÿ')

    return {
        "transcribed_at": datetime.now().isoformat(),
        "language": "ja",
        "char_count": char_count,
        "word_count": word_count,
        "sentence_count": sentence_count,
        "segment_count": len(segments)
    }


def create_structured_json(audio_path, transcription_result, summary):
    """
    æ§‹é€ åŒ–ã•ã‚ŒãŸJSONã‚’ç”Ÿæˆ
    """
    file_metadata = extract_file_metadata(audio_path)
    transcription_metadata = extract_transcription_metadata(
        transcription_result["text"],
        transcription_result["segments"]
    )

    structured_data = {
        "metadata": {
            "file": file_metadata,
            "transcription": transcription_metadata
        },
        "segments": transcription_result["segments"],
        "words": transcription_result["words"],
        "full_text": transcription_result["text"],
        "summary": summary
    }

    return structured_data


def save_json(data, output_path):
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    """
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSONä¿å­˜å®Œäº†: {output_path}")


def main():
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãƒã‚§ãƒƒã‚¯
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: python structured_transcribe.py <éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>")
        sys.exit(1)

    audio_path = sys.argv[1]

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(audio_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_path}")
        sys.exit(1)

    try:
        print(f"ğŸ™ï¸ æ§‹é€ åŒ–æ–‡å­—èµ·ã“ã—é–‹å§‹: {audio_path}")
        print("[1/3] æ–‡å­—èµ·ã“ã—ä¸­ï¼ˆGemini Audio API + è©±è€…è­˜åˆ¥ï¼‰...")

        # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œï¼ˆGemini Audio APIï¼‰
        transcription_result = transcribe_audio_with_gemini(audio_path)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if not transcription_result.get("segments"):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒç©ºã§ã™ï¼‰", file=sys.stderr)
            sys.exit(1)

        print("[2/3] è¦ç´„ç”Ÿæˆä¸­...")

        # è¦ç´„ç”Ÿæˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        summary = summarize_text(transcription_result["text"])

        if summary is None:
            print("  âš ï¸  è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸãŒã€æ–‡å­—èµ·ã“ã—çµæœã¯ä¿å­˜ã•ã‚Œã¾ã™ï¼ˆsummary: nullï¼‰", flush=True)

        print("[3/3] JSONæ§‹é€ åŒ–ä¸­...")

        # æ§‹é€ åŒ–JSONç”Ÿæˆï¼ˆsummaryãŒNoneã§ã‚‚å•é¡Œãªã—ï¼‰
        structured_data = create_structured_json(audio_path, transcription_result, summary)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        base_path = audio_path.rsplit(".", 1)[0]
        json_path = base_path + "_structured.json"

        # JSONä¿å­˜
        save_json(structured_data, json_path)

        # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        print("\nğŸ“Š å‡¦ç†çµ±è¨ˆ:")
        print(f"  æ–‡å­—æ•°: {structured_data['metadata']['transcription']['char_count']}")
        print(f"  å˜èªæ•°: {structured_data['metadata']['transcription']['word_count']}")
        print(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {structured_data['metadata']['transcription']['segment_count']}")

        # è¦ç´„çŠ¶æ…‹è¡¨ç¤º
        if structured_data['summary']:
            print(f"  è¦ç´„: ç”Ÿæˆæ¸ˆã¿ ({len(structured_data['summary'])}æ–‡å­—)")
        else:
            print(f"  è¦ç´„: nullï¼ˆç”Ÿæˆå¤±æ•—ï¼‰")

        # è©±è€…æƒ…å ±è¡¨ç¤º
        if 'speakers' in structured_data and structured_data['speakers']:
            print(f"  è©±è€…æ•°: {len(structured_data['speakers'])}")
            for speaker in structured_data['speakers']:
                print(f"    - {speaker['id']}: {speaker['segment_count']}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

        # Note: Word-level timestampsã¯éå¯¾å¿œï¼ˆGeminiã®åˆ¶ç´„ï¼‰
        if structured_data['words']:
            print(f"  å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ•°: {len(structured_data['words'])}")
        else:
            print(f"  å˜èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: éå¯¾å¿œï¼ˆGemini APIåˆ¶ç´„ï¼‰")

        if structured_data['metadata']['file']['duration_seconds']:
            duration = structured_data['metadata']['file']['duration_seconds']
            print(f"  éŸ³å£°é•·: {duration:.1f}ç§’ ({duration/60:.1f}åˆ†)")

        # [Phase 10-1] è‡ªå‹•ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´
        if os.getenv('AUTO_RENAME_FILES', 'false').lower() == 'true':
            try:
                from generate_smart_filename import (
                    generate_filename_from_transcription,
                    rename_local_files
                )

                print("\nğŸ“ æœ€é©ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆä¸­...")
                new_name = generate_filename_from_transcription(json_path)
                print(f"âœ¨ ææ¡ˆãƒ•ã‚¡ã‚¤ãƒ«å: {new_name}")

                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒãƒ¼ãƒ 
                rename_map = rename_local_files(audio_path, new_name)

                # ãƒ‘ã‚¹æ›´æ–°ï¼ˆçµ±è¨ˆè¡¨ç¤ºå¾Œãªã®ã§ä¸è¦ã ãŒã€å°†æ¥ã®æ‹¡å¼µã®ãŸã‚ï¼‰
                audio_path = str(rename_map[Path(audio_path)])
                json_path = str(rename_map[Path(json_path)])

            except Exception as e:
                print(f"âš ï¸  è‡ªå‹•ãƒªãƒãƒ¼ãƒ å¤±æ•—: {e}")
                print("  æ–‡å­—èµ·ã“ã—çµæœã¯ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")

        print("\nğŸ‰ å®Œäº†!")

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: å‡¦ç†ä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
